{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Content beased filtering using BERT\n",
    "Recommendations using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from nltk.classify.textcat import TextCat\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import multiprocessing\n",
    "\n",
    "from keybert import KeyBERT\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "alt.renderers.enable('mimetype')\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aksel\\AppData\\Local\\Temp\\ipykernel_34768\\3939204259.py:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_books1=pd.read_csv(path +'Books-old.csv')\n"
     ]
    }
   ],
   "source": [
    "path='./Data/'\n",
    "\n",
    "df_books1=pd.read_csv(path +'Books-old.csv') \n",
    "df_books2 = pd.read_csv(path + 'books_1.Best_Books_Ever.csv') #To skip bad lines\n",
    "# df_books2 = pd.read_csv(path + 'books-goodreads.csv', on_bad_lines='skip', dtype=str, low_memory=False)\n",
    "df_ratings=pd.read_csv(path + 'Ratings.csv') \n",
    "df_users=pd.read_csv(path + 'Users.csv') \n",
    "\n",
    "#Renameing\n",
    "df_books2.rename(columns={'title':'Book-Title'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_books1:\n",
      "Shape: (271360, 8)\n",
      "Columns: ['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Image-URL-S', 'Image-URL-M', 'Image-URL-L']\n",
      "\n",
      "df_books2:\n",
      "Shape: (52478, 25)\n",
      "Columns: ['bookId', 'Book-Title', 'series', 'author', 'rating', 'description', 'language', 'isbn', 'genres', 'characters', 'bookFormat', 'edition', 'pages', 'publisher', 'publishDate', 'firstPublishDate', 'awards', 'numRatings', 'ratingsByStars', 'likedPercent', 'setting', 'coverImg', 'bbeScore', 'bbeVotes', 'price']\n"
     ]
    }
   ],
   "source": [
    "print(\"df_books1:\")\n",
    "print(f\"Shape: {df_books1.shape}\")\n",
    "print(f\"Columns: {df_books1.columns.tolist()}\\n\")\n",
    "\n",
    "print(\"df_books2:\")\n",
    "print(f\"Shape: {df_books2.shape}\")\n",
    "print(f\"Columns: {df_books2.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_books_merged:\n",
      "Shape: (27191, 32)\n",
      "Columns: ['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Image-URL-S', 'Image-URL-M', 'Image-URL-L', 'bookId', 'series', 'author', 'rating', 'description', 'language', 'isbn', 'genres', 'characters', 'bookFormat', 'edition', 'pages', 'publisher', 'publishDate', 'firstPublishDate', 'awards', 'numRatings', 'ratingsByStars', 'likedPercent', 'setting', 'coverImg', 'bbeScore', 'bbeVotes', 'price']\n",
      "df_books_merged:\n",
      "Shape: (26965, 32)\n",
      "Columns: ['ISBN', 'Book-Title', 'Book-Author', 'Year-Of-Publication', 'Publisher', 'Image-URL-S', 'Image-URL-M', 'Image-URL-L', 'bookId', 'series', 'author', 'rating', 'description', 'language', 'isbn', 'genres', 'characters', 'bookFormat', 'edition', 'pages', 'publisher', 'publishDate', 'firstPublishDate', 'awards', 'numRatings', 'ratingsByStars', 'likedPercent', 'setting', 'coverImg', 'bbeScore', 'bbeVotes', 'price']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of              ISBN              Book-Title            Book-Author  \\\n",
       "0      0399135782  The Kitchen God's Wife                Amy Tan   \n",
       "1      080410753X  The Kitchen God's Wife                Amy Tan   \n",
       "2      080410753x  The Kitchen God's Wife                Amy Tan   \n",
       "3      1590400356  The Kitchen God's Wife                Amy Tan   \n",
       "4      1558002669  The Kitchen God's Wife                Amy Tan   \n",
       "...           ...                     ...                    ...   \n",
       "27186  0441702902                Radiance           Anne Maybury   \n",
       "27187  0441702902                Radiance           Anne Maybury   \n",
       "27188  0441702902                Radiance           Anne Maybury   \n",
       "27189  0345298608        The Broken Sword       Northam Anderson   \n",
       "27190  0451521390              Pathfinder  James Fenimore Cooper   \n",
       "\n",
       "      Year-Of-Publication         Publisher  \\\n",
       "0                    1991  Putnam Pub Group   \n",
       "1                    1992         Ivy Books   \n",
       "2                    1992         Ivy Books   \n",
       "3                    2002     Phoenix Audio   \n",
       "4                    1991  Audio Literature   \n",
       "...                   ...               ...   \n",
       "27186                1980         Ace Books   \n",
       "27187                1980         Ace Books   \n",
       "27188                1980         Ace Books   \n",
       "27189                1981     Del Rey Books   \n",
       "27190                1982       Signet Book   \n",
       "\n",
       "                                             Image-URL-S  \\\n",
       "0      http://images.amazon.com/images/P/0399135782.0...   \n",
       "1      http://images.amazon.com/images/P/080410753X.0...   \n",
       "2      http://images.amazon.com/images/P/080410753X.0...   \n",
       "3      http://images.amazon.com/images/P/1590400356.0...   \n",
       "4      http://images.amazon.com/images/P/1558002669.0...   \n",
       "...                                                  ...   \n",
       "27186  http://images.amazon.com/images/P/0441702902.0...   \n",
       "27187  http://images.amazon.com/images/P/0441702902.0...   \n",
       "27188  http://images.amazon.com/images/P/0441702902.0...   \n",
       "27189  http://images.amazon.com/images/P/0345298608.0...   \n",
       "27190  http://images.amazon.com/images/P/0451521390.0...   \n",
       "\n",
       "                                             Image-URL-M  \\\n",
       "0      http://images.amazon.com/images/P/0399135782.0...   \n",
       "1      http://images.amazon.com/images/P/080410753X.0...   \n",
       "2      http://images.amazon.com/images/P/080410753X.0...   \n",
       "3      http://images.amazon.com/images/P/1590400356.0...   \n",
       "4      http://images.amazon.com/images/P/1558002669.0...   \n",
       "...                                                  ...   \n",
       "27186  http://images.amazon.com/images/P/0441702902.0...   \n",
       "27187  http://images.amazon.com/images/P/0441702902.0...   \n",
       "27188  http://images.amazon.com/images/P/0441702902.0...   \n",
       "27189  http://images.amazon.com/images/P/0345298608.0...   \n",
       "27190  http://images.amazon.com/images/P/0451521390.0...   \n",
       "\n",
       "                                             Image-URL-L  \\\n",
       "0      http://images.amazon.com/images/P/0399135782.0...   \n",
       "1      http://images.amazon.com/images/P/080410753X.0...   \n",
       "2      http://images.amazon.com/images/P/080410753X.0...   \n",
       "3      http://images.amazon.com/images/P/1590400356.0...   \n",
       "4      http://images.amazon.com/images/P/1558002669.0...   \n",
       "...                                                  ...   \n",
       "27186  http://images.amazon.com/images/P/0441702902.0...   \n",
       "27187  http://images.amazon.com/images/P/0441702902.0...   \n",
       "27188  http://images.amazon.com/images/P/0441702902.0...   \n",
       "27189  http://images.amazon.com/images/P/0345298608.0...   \n",
       "27190  http://images.amazon.com/images/P/0451521390.0...   \n",
       "\n",
       "                             bookId           series  ... firstPublishDate  \\\n",
       "0      12557.The_Kitchen_God_s_Wife              NaN  ...         10/28/91   \n",
       "1      12557.The_Kitchen_God_s_Wife              NaN  ...         10/28/91   \n",
       "2      12557.The_Kitchen_God_s_Wife              NaN  ...         10/28/91   \n",
       "3      12557.The_Kitchen_God_s_Wife              NaN  ...         10/28/91   \n",
       "4      12557.The_Kitchen_God_s_Wife              NaN  ...         10/28/91   \n",
       "...                             ...              ...  ...              ...   \n",
       "27186              7886302-radiance   Riley Bloom #1  ...         08/24/10   \n",
       "27187             24473763-radiance  Wraith Kings #1  ...         02/28/14   \n",
       "27188             18490533-radiance              NaN  ...              NaN   \n",
       "27189       715287.The_Broken_Sword              NaN  ...         11/06/54   \n",
       "27190            8100267-pathfinder    Pathfinder #1  ...         09/01/10   \n",
       "\n",
       "                                                  awards numRatings  \\\n",
       "0                                                     []      76625   \n",
       "1                                                     []      76625   \n",
       "2                                                     []      76625   \n",
       "3                                                     []      76625   \n",
       "4                                                     []      76625   \n",
       "...                                                  ...        ...   \n",
       "27186                                                 []      14852   \n",
       "27187  ['All About Romance (AAR) Annual Reader Poll N...      33252   \n",
       "27188                                                 []       3935   \n",
       "27189                                                 []       5348   \n",
       "27190  ['Locus Award Nominee for Best Young Adult Boo...      21690   \n",
       "\n",
       "                                   ratingsByStars likedPercent  \\\n",
       "0      ['23879', '32998', '16556', '2451', '741']         96.0   \n",
       "1      ['23879', '32998', '16556', '2451', '741']         96.0   \n",
       "2      ['23879', '32998', '16556', '2451', '741']         96.0   \n",
       "3      ['23879', '32998', '16556', '2451', '741']         96.0   \n",
       "4      ['23879', '32998', '16556', '2451', '741']         96.0   \n",
       "...                                           ...          ...   \n",
       "27186     ['3780', '3973', '4639', '1826', '634']         83.0   \n",
       "27187   ['13335', '12072', '5778', '1553', '514']         94.0   \n",
       "27188       ['1204', '1322', '821', '404', '184']         85.0   \n",
       "27189      ['1615', '1960', '1297', '357', '119']         91.0   \n",
       "27190      ['7067', '9053', '4246', '986', '338']         94.0   \n",
       "\n",
       "                            setting  \\\n",
       "0      ['United States of America']   \n",
       "1      ['United States of America']   \n",
       "2      ['United States of America']   \n",
       "3      ['United States of America']   \n",
       "4      ['United States of America']   \n",
       "...                             ...   \n",
       "27186                ['Here & Now']   \n",
       "27187                            []   \n",
       "27188                            []   \n",
       "27189                            []   \n",
       "27190                            []   \n",
       "\n",
       "                                                coverImg bbeScore bbeVotes  \\\n",
       "0      https://i.gr-assets.com/images/S/compressed.ph...     6529      107   \n",
       "1      https://i.gr-assets.com/images/S/compressed.ph...     6529      107   \n",
       "2      https://i.gr-assets.com/images/S/compressed.ph...     6529      107   \n",
       "3      https://i.gr-assets.com/images/S/compressed.ph...     6529      107   \n",
       "4      https://i.gr-assets.com/images/S/compressed.ph...     6529      107   \n",
       "...                                                  ...      ...      ...   \n",
       "27186  https://i.gr-assets.com/images/S/compressed.ph...      623        8   \n",
       "27187  https://i.gr-assets.com/images/S/compressed.ph...      297        4   \n",
       "27188  https://i.gr-assets.com/images/S/compressed.ph...       67        1   \n",
       "27189  https://i.gr-assets.com/images/S/compressed.ph...       50        1   \n",
       "27190  https://i.gr-assets.com/images/S/compressed.ph...      193        2   \n",
       "\n",
       "      price  \n",
       "0      5.26  \n",
       "1      5.26  \n",
       "2      5.26  \n",
       "3      5.26  \n",
       "4      5.26  \n",
       "...     ...  \n",
       "27186  0.85  \n",
       "27187   NaN  \n",
       "27188  5.27  \n",
       "27189  4.04  \n",
       "27190  1.86  \n",
       "\n",
       "[26965 rows x 32 columns]>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merged dataset\n",
    "\n",
    "\n",
    "\n",
    "merged_book_df=pd.merge(df_books1, df_books2, on='Book-Title', how='inner') \n",
    "\n",
    "print(\"df_books_merged:\")\n",
    "print(f\"Shape: {merged_book_df.shape}\")\n",
    "print(f\"Columns: {merged_book_df.columns.tolist()}\")\n",
    "\n",
    "\n",
    "\n",
    "merged_book_df.dropna(subset=[\"description\"], inplace=True)\n",
    "\n",
    "print(\"df_books_merged:\")\n",
    "print(f\"Shape: {merged_book_df.shape}\")\n",
    "print(f\"Columns: {merged_book_df.columns.tolist()}\")\n",
    "\n",
    "merged_book_df.head\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Winnie and Helen have kept each others worst s...\n",
      "1    Winnie and Helen have kept each others worst s...\n",
      "2    Winnie and Helen have kept each others worst s...\n",
      "3    Winnie and Helen have kept each others worst s...\n",
      "4    Winnie and Helen have kept each others worst s...\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "merged_book_df['description'] = merged_book_df['description'].str.replace(r'@\\w+', '<user>', regex=True)\n",
    "\n",
    "merged_book_df['description'] = merged_book_df['description'].str.replace(r'http\\w+', '<url>', regex=True)\n",
    "\n",
    "#list(merged_book_df.description[merged_book_df.Id == 1099555]) #Description with url and html tag\n",
    "\n",
    "merged_book_df['description'] = merged_book_df['description'].str.replace(r'[{}]+'.format(string.punctuation), '', regex=True)\n",
    "\n",
    "\n",
    "print(merged_book_df['description'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machiavellian machiavelli prince noble mercenary'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "model=KeyBERT()\n",
    "\n",
    "def get_keywords_from_description(description):\n",
    "    keywords = model.extract_keywords(description, keyphrase_ngram_range=(1, 1), stop_words=\"english\")\n",
    "    keywords = \" \".join([k[0] for k in keywords])\n",
    "    return keywords\n",
    "\n",
    "get_keywords_from_description(merged_book_df['description'].iloc[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [ISBN, Book-Title, Book-Author, Year-Of-Publication, Publisher, Image-URL-S, Image-URL-M, Image-URL-L, bookId, series, author, rating, description, language, isbn, genres, characters, bookFormat, edition, pages, publisher, publishDate, firstPublishDate, awards, numRatings, ratingsByStars, likedPercent, setting, coverImg, bbeScore, bbeVotes, price]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 32 columns]\n",
      "Shape: (11388, 32)\n",
      "The Kitchen God's Wife\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "duplicates = merged_book_df[merged_book_df.duplicated(subset=['Book-Title', 'description'], keep=False)]\n",
    "print(duplicates)\n",
    "\n",
    "# Remove duplicates\n",
    "merged_book_df = merged_book_df.drop_duplicates(subset=['Book-Title', 'description'])\n",
    "print(f\"Shape: {merged_book_df.shape}\")\n",
    "\n",
    "# make a csv file with the data\n",
    "merged_book_df.to_csv('Data/merged_books.csv', index=False)\n",
    "\n",
    "\n",
    "# Assuming merged_book_df is your dataframe with book descriptions\n",
    "descriptions = merged_book_df['description'].fillna('')\n",
    "\n",
    "#print one title in merged_book_df\n",
    "print(merged_book_df['Book-Title'].iloc[0])\n",
    "\n",
    "# Step 3: Compute the TF-IDF matrix\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(descriptions)\n",
    "\n",
    "# Step 4: Compute the cosine similarity matrix\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6803              Sense of Evil\n",
      "1824                     Chains\n",
      "6988                   Ricochet\n",
      "9839             One for Sorrow\n",
      "5568     The Portrait of a Lady\n",
      "1300                   The Heir\n",
      "9635           Keeping the Moon\n",
      "4905                       Lies\n",
      "11209                Wide Awake\n",
      "11135       The Collected Poems\n",
      "Name: Book-Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the book that matches the title\n",
    "    idx = merged_book_df[merged_book_df['Book-Title'] == title].index[0]\n",
    "\n",
    "    # Get the pairwise similarity scores of all books with that book\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the books based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar books\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the book indices\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    # print(merged_book_df['description'].iloc[book_indices])\n",
    "    \n",
    "    # Return the top 10 most similar books\n",
    "    return merged_book_df['Book-Title'].iloc[book_indices]\n",
    "\n",
    "# Example usage\n",
    "print(get_recommendations(\"Voices\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
