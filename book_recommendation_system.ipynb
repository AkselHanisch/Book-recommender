{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "\n",
    "import scipy\n",
    "import math\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.model_selection import train_test_split \n",
    "from scipy.sparse.linalg import svds \n",
    "from sklearn import preprocessing \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lars\\AppData\\Local\\Temp\\ipykernel_28820\\2624249305.py:3: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_books=pd.read_csv(path +'filtered_books.csv')\n"
     ]
    }
   ],
   "source": [
    "path='./Data/'\n",
    "\n",
    "df_books=pd.read_csv(path +'filtered_books.csv') \n",
    "df_ratings=pd.read_csv(path + 'Ratings.csv') \n",
    "df_users=pd.read_csv(path + 'Users.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1149780, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>278858.00000</td>\n",
       "      <td>168096.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>139429.50000</td>\n",
       "      <td>34.751434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>80499.51502</td>\n",
       "      <td>14.428097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>69715.25000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>139429.50000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>209143.75000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>278858.00000</td>\n",
       "      <td>244.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User-ID            Age\n",
       "count  278858.00000  168096.000000\n",
       "mean   139429.50000      34.751434\n",
       "std     80499.51502      14.428097\n",
       "min         1.00000       0.000000\n",
       "25%     69715.25000      24.000000\n",
       "50%    139429.50000      32.000000\n",
       "75%    209143.75000      44.000000\n",
       "max    278858.00000     244.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_users.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df=pd.merge(df_users,df_ratings,on='User-ID')\n",
    "merged_df=pd.merge(merged_df,df_books,on='ISBN')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_review_counts = df_ratings['ISBN'].value_counts()\n",
    "popular_books = book_review_counts[book_review_counts >= 20].index\n",
    "filtered_ratings = df_ratings[df_ratings['ISBN'].isin(popular_books)]\n",
    "#filtered_ratings.to_csv('data/filtered_ratings.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combined Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Lars\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "c:\\Users\\Lars\\repos\\school projects\\H24\\Book-recommender\\content_based_file.py:35: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_books=pd.read_csv(path +'filtered_books.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISBN\n",
      "006109918X    1.772117\n",
      "0060928336    1.716283\n",
      "0553289063    1.666379\n",
      "0590471570    1.640632\n",
      "0140314202    1.602477\n",
      "0451410742    1.593712\n",
      "0061000043    1.564670\n",
      "0312988249    1.557247\n",
      "880781000X    1.547350\n",
      "1550544683    1.547350\n",
      "8804342838    1.547350\n",
      "3492225926    1.547350\n",
      "2070362388    1.547350\n",
      "3250600555    1.547350\n",
      "1844262553    1.547350\n",
      "8497593588    1.547350\n",
      "207038165X    1.547350\n",
      "0385333404    1.452531\n",
      "0743474325    1.447388\n",
      "0425154637    1.431060\n",
      "dtype: float64\n",
      "Cosine similarity matrix loaded from 'cosine_similarity_matrix.npy'\n",
      "6803              Sense of Evil\n",
      "1824                     Chains\n",
      "6988                   Ricochet\n",
      "9839             One for Sorrow\n",
      "5568     The Portrait of a Lady\n",
      "1300                   The Heir\n",
      "9635           Keeping the Moon\n",
      "4905                       Lies\n",
      "11209                Wide Awake\n",
      "11135       The Collected Poems\n",
      "Name: Book-Title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from content_based_file import get_content_based_recommendations_by_user\n",
    "from user_based_file import get_user_based_recommendations_by_user\n",
    "from nlp_based_file import get_nlp_recommendations_by_user_program\n",
    "\n",
    "\n",
    "\n",
    "#Variables for content based filtering\n",
    "\n",
    "book_review_counts = df_ratings['ISBN'].value_counts()\n",
    "popular_books = book_review_counts[book_review_counts >= 20].index\n",
    "filtered_ratings = df_ratings[df_ratings['ISBN'].isin(popular_books)]\n",
    "\n",
    "user_rating_counts = filtered_ratings['User-ID'].value_counts()\n",
    "active_users = user_rating_counts[user_rating_counts >= 5].index\n",
    "filtered_ratings = filtered_ratings[filtered_ratings['User-ID'].isin(active_users)]\n",
    "\n",
    "\n",
    "user_item_matrix = filtered_ratings.pivot(index='User-ID', columns='ISBN', values='Book-Rating').fillna(0)\n",
    "\n",
    "\n",
    "\n",
    "sparse_matrix = csr_matrix(user_item_matrix.values)\n",
    "sparse_matrix=sparse_matrix.astype('float32')\n",
    "\n",
    "\n",
    "item_similarity = cosine_similarity(sparse_matrix.T)  # Transpose for item-item similarity\n",
    "item_similarity_df = pd.DataFrame(\n",
    "    item_similarity, index=user_item_matrix.columns, columns=user_item_matrix.columns\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similar users:  [165, 136733, 50711, 275610, 96354, 122235, 218836, 207727, 130793, 212009, 33036, 144348, 101299, 78545, 222941, 113618, 37790, 21870, 243607, 191913, 42759, 81854, 486, 28709, 257804, 112818, 96589, 216336, 248850, 112598, 194735, 66591, 250196, 93421, 110493, 189891, 6501, 147687, 82901, 65653, 231694, 179591, 242878, 110165, 80036, 143807, 136104, 266697, 46197, 185468, 55421]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lars\\repos\\school projects\\H24\\Book-recommender\\content_based_file.py:35: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_books=pd.read_csv(path +'filtered_books.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_items([('0768322413', 50), ('0345362721', 49), ('0679408835', 48), ('0446517909', 47), ('0590257889', 46), ('0553802542', 45), ('0802132898', 44), ('0385491050', 43), ('0140042393', 42), ('015610685X', 41), ('0786003677', 50), ('0671870602', 49), ('0671685112', 48), ('0380792923', 47), ('1572460733', 46), ('0750925493', 45), ('0714530387', 44), ('0743467175', 43), ('1582430438', 42), ('0743418700', 41)])\n",
      "           ISBN  user_score  content_score  nlp_score  hybrid_score\n",
      "0    0060928336   10.000000       9.684926        0.0      6.389724\n",
      "7    006109918X    4.021708      10.000000        0.0      4.706512\n",
      "6    0061000043    4.021708       8.829383        0.0      4.296796\n",
      "96   0768322413    0.000000       0.000000       10.0      3.500000\n",
      "10   0061097853    3.518994       6.978607        0.0      3.498211\n",
      "97   0786003677    0.000000       0.000000        9.5      3.325000\n",
      "50   0553289063    0.000000       9.403322        0.0      3.291163\n",
      "51   0590471570    0.000000       9.258033        0.0      3.240312\n",
      "52   0140314202    0.000000       9.042726        0.0      3.164954\n",
      "98   0345362721    0.000000       0.000000        9.0      3.150000\n",
      "53   0451410742    0.000000       8.993263        0.0      3.147642\n",
      "54   0312988249    0.000000       8.787495        0.0      3.075623\n",
      "63   207038165X    0.000000       8.731646        0.0      3.056076\n",
      "62   8497593588    0.000000       8.731646        0.0      3.056076\n",
      "61   1844262553    0.000000       8.731646        0.0      3.056076\n",
      "60   3250600555    0.000000       8.731646        0.0      3.056076\n",
      "59   2070362388    0.000000       8.731646        0.0      3.056076\n",
      "57   8804342838    0.000000       8.731646        0.0      3.056076\n",
      "56   1550544683    0.000000       8.731646        0.0      3.056076\n",
      "55   880781000X    0.000000       8.731646        0.0      3.056076\n",
      "58   3492225926    0.000000       8.731646        0.0      3.056076\n",
      "99   0671870602    0.000000       0.000000        8.5      2.975000\n",
      "64   0385333404    0.000000       8.196584        0.0      2.868804\n",
      "65   0743474325    0.000000       8.167560        0.0      2.858646\n",
      "66   0425154637    0.000000       8.075421        0.0      2.826397\n",
      "100  0679408835    0.000000       0.000000        8.0      2.800000\n",
      "67   0451192613    0.000000       7.977869        0.0      2.792254\n",
      "68   0671002783    0.000000       7.971763        0.0      2.790117\n",
      "69   0515134864    0.000000       7.692482        0.0      2.692369\n",
      "70   014018869X    0.000000       7.678917        0.0      2.687621\n",
      "71   0440961327    0.000000       7.570361        0.0      2.649626\n",
      "101  0671685112    0.000000       0.000000        7.5      2.625000\n",
      "74   0385310161    0.000000       7.404421        0.0      2.591547\n",
      "73   0515122416    0.000000       7.404421        0.0      2.591547\n",
      "72   1551664933    0.000000       7.404421        0.0      2.591547\n",
      "75   0060185074    0.000000       7.340386        0.0      2.569135\n",
      "76   0671870610    0.000000       7.325486        0.0      2.563920\n",
      "77     11238356    0.000000       7.265168        0.0      2.542809\n",
      "78   0307301451    0.000000       7.185178        0.0      2.514812\n",
      "79   0449005909    0.000000       7.181146        0.0      2.513401\n"
     ]
    }
   ],
   "source": [
    "user_weight = 0.3\n",
    "content_weight = 0.35\n",
    "nlp_weight=0.35\n",
    "top_n_recommendations = 50\n",
    "\n",
    "example_user_id = 165\n",
    "\n",
    "\n",
    "\n",
    "def scale_scores(scores, scale_to=10):\n",
    "    max_score = scores.max()\n",
    "    if max_score > 0:  # Avoid division by zero\n",
    "        return (scores / max_score) * scale_to\n",
    "    return scores\n",
    "\n",
    "\n",
    "\n",
    "# User-based recommendations\n",
    "def get_user_based_recommendations(user_id, n=top_n_recommendations):\n",
    "    recommended_items = get_user_based_recommendations_by_user(user_id, n)\n",
    "    return pd.DataFrame({\n",
    "        'ISBN': recommended_items.index,\n",
    "        'user_score': recommended_items.values\n",
    "    })\n",
    "\n",
    "# Content-based recommendations\n",
    "def get_content_based_recommendations(user_id, n=top_n_recommendations):\n",
    "    recommended_items = get_content_based_recommendations_by_user(user_id, n)\n",
    "    return pd.DataFrame({\n",
    "        'ISBN': recommended_items.index,\n",
    "        'content_score': recommended_items.values\n",
    "    })\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "def get_nlp_recommendations(user_id):\n",
    "    n=books_read_by_user_with_description(user_id)*10\n",
    "    recommended_items = get_nlp_recommendations_by_user_program(user_id, n)\n",
    "    return pd.DataFrame({\n",
    "        'ISBN': recommended_items,\n",
    "        'nlp_score': range(len(recommended_items), 0, -1)  # Assign descending scores\n",
    "    })\n",
    "    \n",
    "\n",
    "    \n",
    "def books_read_by_user_with_description(user_id):\n",
    "        user_books = filtered_ratings[filtered_ratings['User-ID'] == user_id]['ISBN'].unique()\n",
    "        return len(user_books)\n",
    "\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "# Combine the three methods\n",
    "def combine_recommendations(user_id, user_weight, content_weight,nlp_weight, n=top_n_recommendations):\n",
    "    # Get top recommendations from both methods\n",
    "    user_based_recs = get_user_based_recommendations(user_id, n)\n",
    "    content_based_recs = get_content_based_recommendations(user_id, n)\n",
    "    nlp_based_recs=get_nlp_recommendations(user_id)\n",
    "    \n",
    "     # Scale scores\n",
    "    user_based_recs['user_score'] = scale_scores(user_based_recs['user_score'])\n",
    "    content_based_recs['content_score'] = scale_scores(content_based_recs['content_score'])\n",
    "    nlp_based_recs['nlp_score']=scale_scores(nlp_based_recs['nlp_score'])\n",
    "    \n",
    "    # Merge on ISBN\n",
    "    combined = pd.merge(user_based_recs, content_based_recs, on='ISBN', how='outer')\n",
    "    combined = pd.merge(combined, nlp_based_recs, on='ISBN', how='outer')\n",
    "\n",
    "    \n",
    "    # Fill missing scores with 0\n",
    "    combined['user_score'] = combined['user_score'].fillna(0)\n",
    "    combined['content_score'] = combined['content_score'].fillna(0)\n",
    "    combined['nlp_score']=combined['nlp_score'].fillna(0)\n",
    "    \n",
    "    # Calculate hybrid score\n",
    "    combined['hybrid_score'] = (user_weight * combined['user_score'] +\n",
    "                                content_weight * combined['content_score']+\n",
    "                                nlp_weight*combined['nlp_score'])\n",
    "    \n",
    "    # Sort by hybrid score\n",
    "    combined = combined.sort_values(by='hybrid_score', ascending=False)\n",
    "    \n",
    "    # Return top recommendations\n",
    "    return combined.head(40)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "final_recommendations = combine_recommendations(example_user_id,user_weight , content_weight,nlp_weight ,n=top_n_recommendations)\n",
    "\n",
    "print(final_recommendations)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
